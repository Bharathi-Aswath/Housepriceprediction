{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn;\n",
    "import datetime as dt;\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# to calculate  which features are more important\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.538713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156915</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-0.203846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.179692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.664615</td>\n",
       "      <td>0.761968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.073791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.146341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.115385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.140313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.520833</td>\n",
       "      <td>-0.146341</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.119231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.136364</td>\n",
       "      <td>-1.064825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.115691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0        -0.6     0.545455  0.538713          1.0   0.250000      0.756098   \n",
       "1        -0.6     0.590909  1.179692          1.0   0.312500      0.829268   \n",
       "2         0.2     0.272727  1.073791          0.0  -0.500000     -0.146341   \n",
       "3         0.2     0.454545  0.140313          1.0  -0.520833     -0.146341   \n",
       "4         1.4    -1.136364 -1.064825          0.0  -0.395833      0.000000   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtFinSF2  TotalBsmtSF  ...  SaleType_ConLI  \\\n",
       "0    0.000000    0.156915       144.0    -0.203846  ...             0.0   \n",
       "1    0.664615    0.761968         0.0     0.655769  ...             0.0   \n",
       "2    0.000000    0.586436         0.0    -0.115385  ...             0.0   \n",
       "3    0.123077    0.335106         0.0    -0.119231  ...             0.0   \n",
       "4    0.000000   -0.115691         0.0     0.561538  ...             0.0   \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0             0.0           0.0           0.0          1.0   \n",
       "1             0.0           0.0           0.0          1.0   \n",
       "2             0.0           0.0           0.0          1.0   \n",
       "3             0.0           0.0           0.0          1.0   \n",
       "4             0.0           0.0           0.0          1.0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                    0.0                   0.0                   0.0   \n",
       "1                    0.0                   0.0                   0.0   \n",
       "2                    0.0                   0.0                   0.0   \n",
       "3                    0.0                   0.0                   0.0   \n",
       "4                    0.0                   0.0                   0.0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                   1.0                    0.0  \n",
       "1                   1.0                    0.0  \n",
       "2                   1.0                    0.0  \n",
       "3                   1.0                    0.0  \n",
       "4                   1.0                    0.0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_all = pd.read_csv('prep_test_rs.csv')\n",
    "X_test_all.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('prep_train_rs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train [ ['GarageCars', 'KitchenQual_TA', 'GrLivArea', 'FullBath', 'TotalBsmtSF',\n",
    "       'YearBuilt', 'GarageArea', '1stFlrSF', 'Fireplaces', 'KitchenQual_Gd',\n",
    "       'BsmtFinSF1', 'TotRmsAbvGrd', '2ndFlrSF', 'BsmtQual_Gd', 'GarageYrBlt',\n",
    "       'Neighborhood_NoRidge', 'Foundation_PConc', 'HalfBath', 'MasVnrArea',\n",
    "       'BedroomAbvGr', 'YearRemodAdd', 'CentralAir_Y', 'LotArea',\n",
    "       'BsmtExposure_Gd', 'GarageType_Detchd', 'BsmtFullBath',\n",
    "       'Exterior1st_BrkFace', 'BsmtFinType1_GLQ', 'GarageFinish_Unf',\n",
    "       'Neighborhood_Crawfor'] ]\n",
    "y_train = train.iloc[:,0]\n",
    "X_test = X_test_all[  ['GarageCars', 'KitchenQual_TA', 'GrLivArea', 'FullBath', 'TotalBsmtSF',\n",
    "       'YearBuilt', 'GarageArea', '1stFlrSF', 'Fireplaces', 'KitchenQual_Gd',\n",
    "       'BsmtFinSF1', 'TotRmsAbvGrd', '2ndFlrSF', 'BsmtQual_Gd', 'GarageYrBlt',\n",
    "       'Neighborhood_NoRidge', 'Foundation_PConc', 'HalfBath', 'MasVnrArea',\n",
    "       'BedroomAbvGr', 'YearRemodAdd', 'CentralAir_Y', 'LotArea',\n",
    "       'BsmtExposure_Gd', 'GarageType_Detchd', 'BsmtFullBath',\n",
    "       'Exterior1st_BrkFace', 'BsmtFinType1_GLQ', 'GarageFinish_Unf',\n",
    "       'Neighborhood_Crawfor']  ]\n",
    "\n",
    "y_train.shape, X_train.shape,X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_train = pd.read_csv('TE_prep_train_rs.csv')\n",
    "\n",
    "TE_y_train =TE_train.iloc[:,0]\n",
    "\n",
    "TE_X_train= TE_train[['GarageCars', 'KitchenQual_TA', 'GrLivArea', 'FullBath', 'GarageArea',\n",
    "       '1stFlrSF', 'YearBuilt', 'TotalBsmtSF', 'KitchenQual_Gd', 'Fireplaces',\n",
    "       'BsmtFinSF1', '2ndFlrSF', 'TotRmsAbvGrd', 'GarageYrBlt', 'BsmtQual_Gd',\n",
    "       'Neighborhood_NoRidge', 'YearRemodAdd', 'BedroomAbvGr', 'CentralAir_Y',\n",
    "       'HalfBath', 'BsmtExposure_Gd', 'MasVnrArea', 'LotArea',\n",
    "       'GarageFinish_Unf', 'GarageType_Detchd', 'BsmtQual_TA',\n",
    "       'BsmtFinType1_GLQ', 'BsmtFullBath', 'Exterior1st_BrkFace',\n",
    "       'Foundation_PConc']]\n",
    "TE_X_test = X_test_all[  ['GarageCars', 'KitchenQual_TA', 'GrLivArea', 'FullBath', 'GarageArea',\n",
    "       '1stFlrSF', 'YearBuilt', 'TotalBsmtSF', 'KitchenQual_Gd', 'Fireplaces',\n",
    "       'BsmtFinSF1', '2ndFlrSF', 'TotRmsAbvGrd', 'GarageYrBlt', 'BsmtQual_Gd',\n",
    "       'Neighborhood_NoRidge', 'YearRemodAdd', 'BedroomAbvGr', 'CentralAir_Y',\n",
    "       'HalfBath', 'BsmtExposure_Gd', 'MasVnrArea', 'LotArea',\n",
    "       'GarageFinish_Unf', 'GarageType_Detchd', 'BsmtQual_TA',\n",
    "       'BsmtFinType1_GLQ', 'BsmtFullBath', 'Exterior1st_BrkFace',\n",
    "       'Foundation_PConc'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 30), (1460,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE_X_train.shape, TE_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model using RF regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 500], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 3, 5], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5, 20]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [100,200,500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5, 20]\n",
    "\n",
    "\n",
    "random_grid = {  'n_estimators': n_estimators,\n",
    "                 'max_features':max_features,\n",
    "                 'max_depth' :max_depth,\n",
    "                 'min_samples_split' : min_samples_split,\n",
    "                 'min_samples_leaf':min_samples_leaf }\n",
    "print(random_grid)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each iteration, the algorithm will choose a difference combination of the features. Altogether, there are 3 * 2 * 3 * 3 * 4 = 216 settings! However, the benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation (we use 100 and 3 respectively). More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf= RandomForestRegressor(random_state = 20)\n",
    "rf_random = RandomizedSearchCV (estimator=rf, param_distributions = random_grid,  n_iter = 10, cv = 5, verbose = 2, random_state=9, n_jobs=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=2, max_features=auto, min_samples_leaf=20, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=auto, min_samples_leaf=20, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=auto, min_samples_leaf=20, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=auto, min_samples_leaf=20, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=auto, min_samples_leaf=20, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=1,\n",
       "                   param_distributions={'max_depth': [2, 3, 5],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 20],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 500]},\n",
       "                   random_state=9, scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters\n",
    "# search across 10 different combinations,using 3 fold cross validation, and use all available cores(njobs=-1  means no limit)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring = 'neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=9, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, min_samples_leaf=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = rf_random.best_params_\n",
    "\n",
    "rf_reg = RandomForestRegressor(**best_params)\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rcv = rf_random.predict(X_test)\n",
    "\n",
    "predictions_rcv.shape\n",
    "#here predictions is a 1d array(dseries)( but sklearn expects a dataframe(2d))\n",
    "predictions_rcv = predictions_rcv.reshape(-1,1)\n",
    "predictions_rcv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting model with nonscaled target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 500], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 3, 5], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5, 20]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [100,200,500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5, 20]\n",
    "\n",
    "\n",
    "TE_random_grid = {  'n_estimators': n_estimators,\n",
    "                 'max_features':max_features,\n",
    "                 'max_depth' :max_depth,\n",
    "                 'min_samples_split' : min_samples_split,\n",
    "                 'min_samples_leaf':min_samples_leaf }\n",
    "print(TE_random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 3, 5],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 20],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 500]},\n",
       "                   random_state=9, scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TE_rf = RandomForestRegressor()\n",
    "TE_rf_random = RandomizedSearchCV(estimator = rf, param_distributions = TE_random_grid,scoring = 'neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=9, n_jobs = -1)\n",
    "\n",
    "\n",
    "TE_rf_random.fit(TE_X_train,TE_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " TE_rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with better score(30features,rcv,nonscaled target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126894.01736911],\n",
       "       [153279.14298571],\n",
       "       [185999.19718123],\n",
       "       ...,\n",
       "       [153301.44223675],\n",
       "       [123751.32098703],\n",
       "       [256717.2002553 ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE_predictions_rcv = TE_rf_random.predict(TE_X_test)\n",
    "\n",
    "TE_predictions_rcv.shape\n",
    "#here predictions is a 1d array(dseries)( but sklearn expects a dataframe(2d))\n",
    "TE_predictions_rcv = TE_predictions_rcv.reshape(-1,1)\n",
    "TE_predictions_rcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_best_params = TE_rf_random.best_params_\n",
    "\n",
    "TE_rf_reg = RandomForestRegressor(**TE_best_params)\n",
    "TE_rf_reg.fit(TE_X_train, TE_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125493.16979191],\n",
       "       [153727.41805933],\n",
       "       [185147.63062713],\n",
       "       ...,\n",
       "       [153146.71987609],\n",
       "       [123646.79089586],\n",
       "       [259658.28635372]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE_predictions_reg = TE_rf_reg.predict(TE_X_test)\n",
    "#here predictions is a 1d array(dseries)( but sklearn expects a dataframe(2d))\n",
    "TE_predictions_reg = TE_predictions_reg.reshape(-1,1)\n",
    "TE_predictions_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exporting output to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_predictions_reg = pd.DataFrame (TE_predictions_reg, columns = ['SalePrice'])\n",
    "\n",
    "TE_predictions_reg.to_csv('TE_predictions_reg.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TE_predictions_rcv = pd.DataFrame (TE_predictions_rcv, columns = ['SalePrice'])\n",
    "\n",
    "TE_predictions_rcv.to_csv('TE_predictions_rcv.csv', index= False)\n",
    "\n",
    "#this one gave better prediction (nonscaled target with randomized search cv than the base model(rf_reg)), \n",
    "#now lets try with 22 features #tried iis not giving the best score so use 30 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rcv = pd.DataFrame (predictions_rcv, columns = ['SalePrice'])\n",
    "\n",
    "predictions_rcv.to_csv('predictions_rcv.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing base model performance with rcv\n",
    "rf_reg = RandomForestRegressor(n_estimators = 10, random_state = 9)\n",
    "rf_reg.fit(train_features, train_labels)\n",
    "base_accuracy = evaluate(base_model, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(train_features, train_labels)\n",
    "base_accuracy = evaluate(base_model, test_features, test_labels)\n",
    "Model Performance\n",
    "Average Error: 3.9199 degrees.\n",
    "Accuracy = 93.36%.\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, test_features, test_labels)\n",
    "Model Performance\n",
    "Average Error: 3.7152 degrees.\n",
    "Accuracy = 93.73%.\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "Improvement of 0.40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('random_forest_house_regression.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(rf_random, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
